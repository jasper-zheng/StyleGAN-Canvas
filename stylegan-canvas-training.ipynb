{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training StyleGAN-Canvas\n",
    "\n",
    "This is a notebook for training [StyleGAN-Canvas](https://github.com/jasper-zheng/StyleGAN-Canvas).  \n",
    "\n",
    "Author: Jasper Zheng (Shuoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup  \n",
    "\n",
    "Please make sure you're running a GPU runtime.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clone Repo and Install Dependencies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'StyleGAN-Canvas' already exists and is not an empty directory.\n",
      "/notebooks/StyleGAN-Canvas\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from -r ./requirements.txt (line 2)) (1.23.1)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.9/dist-packages (from -r ./requirements.txt (line 3)) (8.1.3)\n",
      "Collecting pillow==8.3.1\n",
      "  Downloading Pillow-8.3.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.7.1\n",
      "  Downloading scipy-1.7.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.5/28.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests==2.26.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm==4.62.2\n",
      "  Downloading tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ninja==1.10.2\n",
      "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib==3.4.2\n",
      "  Downloading matplotlib-3.4.2-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting imageio==2.9.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting imgui==1.3.0\n",
      "  Downloading imgui-1.3.0-cp39-cp39-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting glfw==2.2.0\n",
      "  Downloading glfw-2.2.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/204.8 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyopengl==3.1.5\n",
      "  Downloading PyOpenGL-3.1.5-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n",
      "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyspng\n",
      "  Downloading pyspng-0.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kornia\n",
      "  Downloading kornia-0.6.10-py2.py3-none-any.whl (612 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.0/612.0 kB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kmeans_pytorch\n",
      "  Downloading kmeans_pytorch-0.3-py3-none-any.whl (4.4 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests==2.26.0->-r ./requirements.txt (line 6)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests==2.26.0->-r ./requirements.txt (line 6)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests==2.26.0->-r ./requirements.txt (line 6)) (1.26.10)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.4.2->-r ./requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.4.2->-r ./requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.4.2->-r ./requirements.txt (line 9)) (1.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.4.2->-r ./requirements.txt (line 9)) (3.0.9)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from kornia->-r ./requirements.txt (line 16)) (21.3)\n",
      "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from kornia->-r ./requirements.txt (line 16)) (1.12.0+cu116)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.4.2->-r ./requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia->-r ./requirements.txt (line 16)) (4.3.0)\n",
      "Installing collected packages: pyopengl, ninja, imgui, glfw, tqdm, pillow, numpy, kmeans_pytorch, imageio-ffmpeg, charset-normalizer, scipy, requests, pyspng, matplotlib, kornia, imageio\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.1\n",
      "    Uninstalling numpy-1.23.1:\n",
      "      Successfully uninstalled numpy-1.23.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.1.0\n",
      "    Uninstalling charset-normalizer-2.1.0:\n",
      "      Successfully uninstalled charset-normalizer-2.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.8.1\n",
      "    Uninstalling scipy-1.8.1:\n",
      "      Successfully uninstalled scipy-1.8.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.2\n",
      "    Uninstalling matplotlib-3.5.2:\n",
      "      Successfully uninstalled matplotlib-3.5.2\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.19.3\n",
      "    Uninstalling imageio-2.19.3:\n",
      "      Successfully uninstalled imageio-2.19.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.0+cu116 requires pillow!=8.3.*,>=5.3.0, but you have pillow 8.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed charset-normalizer-2.0.12 glfw-2.2.0 imageio-2.9.0 imageio-ffmpeg-0.4.3 imgui-1.3.0 kmeans_pytorch-0.3 kornia-0.6.10 matplotlib-3.4.2 ninja-1.10.2 numpy-1.22.4 pillow-8.3.1 pyopengl-3.1.5 pyspng-0.1.1 requests-2.26.0 scipy-1.7.1 tqdm-4.62.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: jax 0.3.14\n",
      "Uninstalling jax-0.3.14:\n",
      "  Successfully uninstalled jax-0.3.14\n",
      "Found existing installation: jaxlib 0.3.8+cuda11.cudnn82\n",
      "Uninstalling jaxlib-0.3.8+cuda11.cudnn82:\n",
      "  Successfully uninstalled jaxlib-0.3.8+cuda11.cudnn82\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
      "Collecting jax[cuda11_cudnn805]==0.3.10\n",
      "  Downloading jax-0.3.10.tar.gz (939 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.22.4)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.7.1)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (4.3.0)\n",
      "Collecting jaxlib==0.3.10+cuda11.cudnn805\n",
      "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.10%2Bcuda11.cudnn805-cp39-none-manylinux2014_x86_64.whl (175.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.7/175.7 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.9/dist-packages (from jaxlib==0.3.10+cuda11.cudnn805->jax[cuda11_cudnn805]==0.3.10) (1.12)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.3.10-py3-none-any.whl size=1088051 sha256=b74861a72200fc14e405f0f1f877b64aab654968072588806d60223d10344376\n",
      "  Stored in directory: /root/.cache/pip/wheels/14/4a/ff/e9ddfa09012c67d22f926a7873c546c04e722969e8d86f84ec\n",
      "Successfully built jax\n",
      "Installing collected packages: jaxlib, jax\n",
      "Successfully installed jax-0.3.10 jaxlib-0.3.10+cuda11.cudnn805\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jasper-zheng/StyleGAN-Canvas.git  \n",
    "%cd StyleGAN-Canvas\n",
    "!pip install -r ./requirements.txt\n",
    "\n",
    "!pip uninstall jax jaxlib -y\n",
    "!pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Download and Prepare Dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [FFHQ](https://github.com/NVlabs/ffhq-dataset) (Unaligned) 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./StyleGAN-Canvas\n",
    "!gdown 1Sqd0e_O7-ksCwt-4Kun6qVjkL7L8L6nG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-process pipeline is defined in `./training/pipeline.py`, edit the code to change the pipeline. We use gaussian filter for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/StyleGAN-Canvas\n"
     ]
    }
   ],
   "source": [
    "%cd ./StyleGAN-Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = '/notebooks/StyleGAN-Canvas/ffhq-u-256x256.zip'\n",
    "batch_size = 32\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dnnlib\n",
    "import torch\n",
    "from torch_utils import misc\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.utils import make_grid\n",
    "from IPython import display\n",
    "from training.pipeline import Preprocess\n",
    "\n",
    "def init_dataset_kwargs(data):\n",
    "    try:\n",
    "        dataset_kwargs = dnnlib.EasyDict(class_name='training.dataset.ImageFolderDataset', path=data, use_labels=True, max_size=None, xflip=False)\n",
    "        dataset_obj = dnnlib.util.construct_class_by_name(**dataset_kwargs) # Subclass of training.dataset.Dataset.\n",
    "        dataset_kwargs.resolution = dataset_obj.resolution # Be explicit about resolution.\n",
    "        dataset_kwargs.use_labels = dataset_obj.has_labels # Be explicit about labels.\n",
    "        dataset_kwargs.max_size = len(dataset_obj) # Be explicit about dataset size.\n",
    "        return dataset_kwargs, dataset_obj.name\n",
    "    except IOError as err:\n",
    "        raise click.ClickException(f'--data: {err}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_kwargs, dataset_name = init_dataset_kwargs(dataset_file)\n",
    "training_set_kwargs.use_labels = False\n",
    "training_set_kwargs.xflip = False\n",
    "\n",
    "data_loader_kwargs = dnnlib.EasyDict(pin_memory=True, prefetch_factor=2)\n",
    "training_set = dnnlib.util.construct_class_by_name(**training_set_kwargs)\n",
    "\n",
    "training_set_sampler = misc.InfiniteSampler(dataset=training_set, rank=0, num_replicas=1, seed=0)\n",
    "training_set_iterator = iter(torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                                         sampler=training_set_sampler, \n",
    "                                                         batch_size=batch_size//1, \n",
    "                                                         **data_loader_kwargs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process the ground truth images to condition images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_real_img, _ = next(training_set_iterator)\n",
    "phase_real_img = torch.clamp(phase_real_img.to(device).to(torch.float32) / 127.5 - 1, -1, 1)\n",
    "\n",
    "pre_process = Preprocess().to(device)\n",
    "processed = pre_process.preprocess_to_conditions(phase_real_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showcase the ground truth images and the processed conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_true = make_grid(phase_real_img[:4], nrow = 4)\n",
    "grid_cond = make_grid(processed[:4], nrow = 4)\n",
    "grid = torch.cat((grid_true,grid_cond),dim=1)\n",
    "display.display(to_pil_image(grid.add(1).div(2).cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/StyleGAN-Canvas\n"
     ]
    }
   ],
   "source": [
    "%cd ./StyleGAN-Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan_canvas.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 1024,\n",
      "    \"encode_rgb\": 0,\n",
      "    \"blur_sigma\": 0,\n",
      "    \"magnitude_ema_beta\": 0.9988915792636801,\n",
      "    \"conv_kernel\": 1,\n",
      "    \"connection_start\": 0,\n",
      "    \"connection_end\": 12,\n",
      "    \"connection_grow_from\": 4,\n",
      "    \"num_appended_ws\": 15,\n",
      "    \"use_radial_filters\": true\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
      "    \"block_kwargs\": {\n",
      "      \"freeze_layers\": 0\n",
      "    },\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 16384,\n",
      "    \"channel_max\": 512\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.0025\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.002\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 2.0,\n",
      "    \"blur_init_sigma\": 10,\n",
      "    \"blur_fade_kimg\": 220.0\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"num_workers\": 3\n",
      "  },\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"/notebooks/StyleGAN-Canvas/ffhq-u-256x256.zip\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 70324,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 256,\n",
      "    \"random_seed\": 0\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"batch_size\": 32,\n",
      "  \"batch_gpu\": 16,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_small\"\n",
      "  ],\n",
      "  \"total_kimg\": 25000,\n",
      "  \"switch_to_vgg\": 200,\n",
      "  \"gan_factor\": 0.9,\n",
      "  \"target_factor\": 0.8,\n",
      "  \"d_factor\": 1.0,\n",
      "  \"kimg_per_tick\": 4,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 10,\n",
      "  \"random_seed\": 0,\n",
      "  \"ema_kimg\": 10.0,\n",
      "  \"connection_grow_step\": 96,\n",
      "  \"connection_grow_kimg\": 9999999,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"ada_target\": 0.6,\n",
      "  \"run_dir\": \"/notebooks/runs/ffhq-512-blur-f/00004-stylegan-canvas-r-ffhq-u-256x256-gpus1-batch32-gamma2\"\n",
      "}\n",
      "\n",
      "Output directory:    /notebooks/runs/ffhq-512-blur-f/00004-stylegan-canvas-r-ffhq-u-256x256-gpus1-batch32-gamma2\n",
      "Number of GPUs:      1\n",
      "Batch size:          32 images\n",
      "Training duration:   25000 kimg\n",
      "Dataset path:        /notebooks/StyleGAN-Canvas/ffhq-u-256x256.zip\n",
      "Dataset size:        70324 images\n",
      "Dataset resolution:  256\n",
      "Dataset labels:      False\n",
      "Dataset x-flips:     False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "\n",
      "Num images:  70324\n",
      "Image shape: [3, 256, 256]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "img_resolution:256\n",
      "hiiii generator\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 3, 2, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 512, 512, 512, 512, 0]\n",
      "SynthesisLayer resolution: [16, 16, 16, 32, 32, 64, 64, 128, 128, 128, 256, 256, 256, 236, 236]\n",
      "hiiii appended net\n",
      "[128, 64, 32, 32, 16, 16, 16, 16, 8, 4]\n",
      "[0, 0, 0, 5, 4, 3, 2, 1, 0, 0]\n",
      "[64, 256, 512, 512, 512, 512, 512, 512, 1024, 1024]\n",
      "padding 10\n",
      "AL0_R128_C256_0\t fp16: True\n",
      "AL1_R64_C512_0\t fp16: True\n",
      "AL2_R32_C512_0\t fp16: True\n",
      "AL3_R32_C512_5\t fp16: True\n",
      "AL4_R16_C512_4\t fp16: False\n",
      "AL5_R16_C512_3\t fp16: False\n",
      "AL6_R16_C512_2\t fp16: False\n",
      "AL7_R16_C1024_1\t fp16: False\n",
      "AL8_R8_C1024_0\t fp16: False\n",
      "AL9_R4_C1024_0\t fp16: False\n",
      "last skip shape: 4\n",
      "epilogue: (1024, 4, 4)\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
      "\n",
      "Generator                                  Parameters  Buffers  Output shape         Datatype\n",
      "---                                        ---         ---      ---                  ---     \n",
      "appended_net.in_proj.act                   -           -        [16, 32, 256, 256]   float16 \n",
      "appended_net.in_proj                       128         1        [16, 32, 256, 256]   float16 \n",
      "appended_net.AL0_R128_C256_0.batch_norm    64          65       [16, 32, 256, 256]   float16 \n",
      "appended_net.AL0_R128_C256_0.skip_mapping  8448        1        [16, 256, 128, 128]  float16 \n",
      "appended_net.AL0_R128_C256_0.conv1         18496       1        [16, 64, 256, 256]   float16 \n",
      "appended_net.AL0_R128_C256_0.conv2         147712      1        [16, 256, 128, 128]  float16 \n",
      "appended_net.AL0_R128_C256_0               -           -        [16, 256, 128, 128]  float16 \n",
      "appended_net.AL1_R64_C512_0.batch_norm     512         513      [16, 256, 128, 128]  float16 \n",
      "appended_net.AL1_R64_C512_0.skip_mapping   131584      1        [16, 512, 64, 64]    float16 \n",
      "appended_net.AL1_R64_C512_0.conv1          590080      1        [16, 256, 128, 128]  float16 \n",
      "appended_net.AL1_R64_C512_0.conv2          1180160     1        [16, 512, 64, 64]    float16 \n",
      "appended_net.AL1_R64_C512_0                -           -        [16, 512, 64, 64]    float16 \n",
      "appended_net.AL2_R32_C512_0.batch_norm     1024        1025     [16, 512, 64, 64]    float16 \n",
      "appended_net.AL2_R32_C512_0.skip_mapping   262656      1        [16, 512, 32, 32]    float16 \n",
      "appended_net.AL2_R32_C512_0.conv1          2359808     1        [16, 512, 64, 64]    float16 \n",
      "appended_net.AL2_R32_C512_0.conv2          2359808     1        [16, 512, 32, 32]    float16 \n",
      "appended_net.AL2_R32_C512_0                -           -        [16, 512, 32, 32]    float16 \n",
      "appended_net.AL3_R32_C512_5.batch_norm     1024        1025     [16, 512, 32, 32]    float16 \n",
      "appended_net.AL3_R32_C512_5.skip_mapping   262656      1        [16, 512, 32, 32]    float16 \n",
      "appended_net.AL3_R32_C512_5.conv1          2359808     1        [16, 512, 32, 32]    float16 \n",
      "appended_net.AL3_R32_C512_5.conv2          2359808     1        [16, 512, 32, 32]    float16 \n",
      "appended_net.AL3_R32_C512_5                -           -        [16, 512, 32, 32]    float16 \n",
      "appended_net.AL4_R16_C512_4.batch_norm     1024        1025     [16, 512, 32, 32]    float32 \n",
      "appended_net.AL4_R16_C512_4.skip_mapping   262656      1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL4_R16_C512_4.conv1          2359808     1        [16, 512, 32, 32]    float32 \n",
      "appended_net.AL4_R16_C512_4.conv2          2359808     1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL4_R16_C512_4                -           -        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL5_R16_C512_3.batch_norm     1024        1025     [16, 512, 16, 16]    float32 \n",
      "appended_net.AL5_R16_C512_3.skip_mapping   262656      1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL5_R16_C512_3.conv1          2359808     1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL5_R16_C512_3.conv2          2359808     1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL5_R16_C512_3                -           -        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL6_R16_C512_2.batch_norm     1024        1025     [16, 512, 16, 16]    float32 \n",
      "appended_net.AL6_R16_C512_2.skip_mapping   262656      1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL6_R16_C512_2.conv1          2359808     1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL6_R16_C512_2.conv2          2359808     1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL6_R16_C512_2                -           -        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL7_R16_C1024_1.batch_norm    1024        1025     [16, 512, 16, 16]    float32 \n",
      "appended_net.AL7_R16_C1024_1.skip_mapping  525312      1        [16, 1024, 16, 16]   float32 \n",
      "appended_net.AL7_R16_C1024_1.conv1         2359808     1        [16, 512, 16, 16]    float32 \n",
      "appended_net.AL7_R16_C1024_1.conv2         4719616     1        [16, 1024, 16, 16]   float32 \n",
      "appended_net.AL7_R16_C1024_1               -           -        [16, 1024, 16, 16]   float32 \n",
      "appended_net.AL8_R8_C1024_0.batch_norm     2048        2049     [16, 1024, 16, 16]   float32 \n",
      "appended_net.AL8_R8_C1024_0.skip_mapping   1049600     1        [16, 1024, 8, 8]     float32 \n",
      "appended_net.AL8_R8_C1024_0.conv1          9438208     1        [16, 1024, 16, 16]   float32 \n",
      "appended_net.AL8_R8_C1024_0.conv2          9438208     1        [16, 1024, 8, 8]     float32 \n",
      "appended_net.AL8_R8_C1024_0                -           -        [16, 1024, 8, 8]     float32 \n",
      "appended_net.AL9_R4_C1024_0.batch_norm     2048        2049     [16, 1024, 8, 8]     float32 \n",
      "appended_net.AL9_R4_C1024_0.skip_mapping   1049600     1        [16, 1024, 4, 4]     float32 \n",
      "appended_net.AL9_R4_C1024_0.conv1          9438208     1        [16, 1024, 8, 8]     float32 \n",
      "appended_net.AL9_R4_C1024_0.conv2          9438208     1        [16, 1024, 4, 4]     float32 \n",
      "appended_net.AL9_R4_C1024_0                -           -        [16, 1024, 4, 4]     float32 \n",
      "appended_net.epilogue.mapping_in           524800      -        [16, 512]            float32 \n",
      "appended_net.epilogue.mapping              525312      512      [16, 16, 512]        float32 \n",
      "mapping.fc0                                262656      -        [16, 512]            float32 \n",
      "mapping.fc1                                262656      -        [16, 512]            float32 \n",
      "mapping                                    -           512      [16, 16, 512]        float32 \n",
      "synthesis.input.conv                       1049600     -        [16, 1024, 16, 16]   float32 \n",
      "synthesis.input                            -           -        [16, 1024, 36, 36]   float32 \n",
      "synthesis.L0_36_1024.affine                525312      -        [16, 1024]           float32 \n",
      "synthesis.L0_36_1024                       1049600     157      [16, 1024, 36, 36]   float32 \n",
      "synthesis.L1_36_1024.affine                525312      -        [16, 1024]           float32 \n",
      "synthesis.L1_36_1024                       1050112     157      [16, 1536, 36, 36]   float32 \n",
      "synthesis.L2_36_1024.affine                787968      -        [16, 1536]           float32 \n",
      "synthesis.L2_36_1024                       1574400     157      [16, 1536, 36, 36]   float32 \n",
      "synthesis.L3_52_1024.affine                787968      -        [16, 1536]           float32 \n",
      "synthesis.L3_52_1024                       1574400     169      [16, 1536, 52, 52]   float32 \n",
      "synthesis.L4_52_1024.affine                787968      -        [16, 1536]           float32 \n",
      "synthesis.L4_52_1024                       1574400     157      [16, 1536, 52, 52]   float32 \n",
      "synthesis.L5_84_1024.affine                787968      -        [16, 1536]           float32 \n",
      "synthesis.L5_84_1024                       1573888     169      [16, 1024, 84, 84]   float16 \n",
      "synthesis.L6_84_1024.affine                525312      -        [16, 1024]           float32 \n",
      "synthesis.L6_84_1024                       1049600     157      [16, 1024, 84, 84]   float16 \n",
      "synthesis.L7_148_724.affine                525312      -        [16, 1024]           float32 \n",
      "synthesis.L7_148_724                       742100      169      [16, 724, 148, 148]  float16 \n",
      "synthesis.L8_148_512.affine                371412      -        [16, 724]            float32 \n",
      "synthesis.L8_148_512                       371200      157      [16, 512, 148, 148]  float16 \n",
      "synthesis.L9_148_362.affine                262656      -        [16, 512]            float32 \n",
      "synthesis.L9_148_362                       185706      157      [16, 362, 148, 148]  float16 \n",
      "synthesis.L10_276_256.affine               185706      -        [16, 362]            float32 \n",
      "synthesis.L10_276_256                      92928       169      [16, 256, 276, 276]  float16 \n",
      "synthesis.L11_276_181.affine               131328      -        [16, 256]            float32 \n",
      "synthesis.L11_276_181                      46517       157      [16, 181, 276, 276]  float16 \n",
      "synthesis.L12_276_128.affine               92853       -        [16, 181]            float32 \n",
      "synthesis.L12_276_128                      23296       25       [16, 128, 276, 276]  float16 \n",
      "synthesis.L13_256_128.affine               65664       -        [16, 128]            float32 \n",
      "synthesis.L13_256_128                      16512       25       [16, 128, 256, 256]  float16 \n",
      "synthesis.L14_256_3.affine                 65664       -        [16, 128]            float32 \n",
      "synthesis.L14_256_3                        387         1        [16, 3, 256, 256]    float16 \n",
      "synthesis                                  -           1        [16, 3, 256, 256]    float32 \n",
      "---                                        ---         ---      ---                  ---     \n",
      "Total                                      94434025    13865    -                    -       \n",
      "\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
      "---            ---         ---      ---                  ---     \n",
      "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
      "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
      "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
      "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
      "b256           -           16       [16, 128, 128, 128]  float16 \n",
      "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
      "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
      "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
      "b128           -           16       [16, 256, 64, 64]    float16 \n",
      "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
      "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
      "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
      "b64            -           16       [16, 512, 32, 32]    float16 \n",
      "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
      "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
      "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
      "b32            -           16       [16, 512, 16, 16]    float16 \n",
      "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
      "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
      "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
      "b16            -           16       [16, 512, 8, 8]      float32 \n",
      "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
      "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
      "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
      "b8             -           16       [16, 512, 4, 4]      float32 \n",
      "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
      "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
      "b4.fc          4194816     -        [16, 512]            float32 \n",
      "b4.out         513         -        [16, 1]              float32 \n",
      "---            ---         ---      ---                  ---     \n",
      "Total          24001089    416      -                    -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 1 GPUs...\n",
      "Setting up training phases...\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Exporting sample images...\n",
      "(30, 16) (480, 3, 256, 256) (480, 0)\n",
      "grid_p min max: -1.0 1.0\n",
      "processed grid_p min max: -0.9987190365791321 1.000000238418579\n",
      "Initializing logs...\n",
      "Training for 25000 kimg...\n",
      "\n",
      "net_err: 1.46779\t main_err: 0.718175\t target_err: 1.0268\n",
      "loss_D: 0.718173\n",
      "loss_D: 0.00534926\n",
      "tick 0     kimg 0.0      cpumem 4.52   gpumem 13.59  reserved 14.44  augment 0.000\n",
      "Evaluating metrics skipped\n",
      "net_err: 2.42224\t main_err: 1.8059\t target_err: 0.996165\n",
      "loss_D: 0.712649\n",
      "net_err: 3.76508\t main_err: 3.26922\t target_err: 1.02848\n",
      "loss_D: 0.379147\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "outdir = '/notebooks/runs/ffhq-256-blur'\n",
    "dataset_file = '/notebooks/StyleGAN-Canvas/ffhq-u-256x256.zip'\n",
    "batch = 32\n",
    "gamma = 2\n",
    "cmax = 512\n",
    "cbase = 16384\n",
    "switch_to_vgg = 200\n",
    "\n",
    "batch_gpu = 16\n",
    "snap = 10\n",
    "\n",
    "!python train.py --outdir={outdir} --cfg=stylegan-canvas-r --data={dataset_file} --gpus=1 --batch={batch} --gamma={gamma} --aug=ada --cmax={cmax} --cbase={cbase} --batch-gpu={batch_gpu} --switch-to-vgg={switch_to_vgg} --snap={snap}       \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "guaMEEvlzHjd"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
